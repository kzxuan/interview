# 过拟合与正则化

#### 什么是欠拟合和过拟合

- 欠拟合指模型不能在训练集上获得**足够低的训练误差**。
- 过拟合指模型的训练误差与测试误差（**泛化误差**）之间差距过大。反映在评价指标上，就是模型在训练集上表现良好，但是在测试集和新数据上表现一般（**泛化能力差**）。

#### 有哪些降低欠拟合风险的方法
- 加入新的特征
  交叉特征、多项式特征。
- 在深度学习中使用
  因子分解机、Deep-Crossing、自编码器。
- 增加模型复杂度
  线性模型：添加高次项；
  神经网络：**增加网络层数、神经元个数**。
- 减小正则化项的系数
  添加正则化项是为了限制模型的学习能力，减小正则化项的系数则可以放宽这个限制。模型通常更倾向于更大的权重，**更大的权重**可以使模型更好的拟合数据。

#### 有哪些降低过拟合风险的方法
- 数据增强
  图像：平移、旋转、缩放。
  利用生成对抗网络（GAN）生成新数据。
  NLP：利用机器翻译生成新数据。
- 降低模型复杂度
  神经网络：减少网络层、神经元个数。
  决策树：降低树的深度、剪枝。
- 权值约束（添加正则化项），L1 正则化或L2 正则化。
  集成学习
  神经网络：Dropout。
  决策树：随机森林、GBDT。
- 提前终止


